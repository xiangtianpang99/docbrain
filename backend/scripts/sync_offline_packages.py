"""
docBrain ç¦»çº¿ä¾èµ–æ™ºèƒ½åŒæ­¥å·¥å…·

åŠŸèƒ½ï¼š
1. é€ä¸ªæ£€æŸ¥ requirements.txt ä¸­çš„ä¾èµ–åŠå…¶å­ä¾èµ–
2. ä»…ä¸‹è½½ç¼ºå¤±çš„ wheel æ–‡ä»¶ï¼Œè·³è¿‡å·²æœ‰çš„
3. åˆ é™¤ä¸å†éœ€è¦çš„å¤šä½™ wheel æ–‡ä»¶
4. åœ¨ exportLog/ ç›®å½•ä¸‹ç”Ÿæˆå˜æ›´æ—¥å¿— + æ–°å¢ wheel æ–‡ä»¶å‰¯æœ¬
"""

import os
import sys
import shutil
import subprocess
import json
import time
import threading
from datetime import datetime
from pathlib import Path


# ============================================================
# è¿›åº¦æ˜¾ç¤ºå·¥å…·
# ============================================================

def progress_bar(current, total, prefix="", width=40):
    """æ‰“å°ä¸€è¡Œå†…æ›´æ–°çš„è¿›åº¦æ¡"""
    if total == 0:
        return
    pct = current / total
    filled = int(width * pct)
    bar = "â–ˆ" * filled + "â–‘" * (width - filled)
    sys.stdout.write(f"\r  {prefix} [{bar}] {current}/{total} ({pct:.0%})")
    sys.stdout.flush()
    if current >= total:
        sys.stdout.write("\n")
        sys.stdout.flush()


class Spinner:
    """æ—‹è½¬åŠ¨ç”»ï¼Œç”¨äºæ— æ³•ç¡®å®šæ€»é‡çš„é•¿è€—æ—¶æ“ä½œ"""
    FRAMES = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]

    def __init__(self, message="å¤„ç†ä¸­"):
        self.message = message
        self._stop = threading.Event()
        self._thread = None
        self._elapsed = 0

    def _spin(self):
        start = time.time()
        i = 0
        while not self._stop.is_set():
            self._elapsed = time.time() - start
            frame = self.FRAMES[i % len(self.FRAMES)]
            sys.stdout.write(f"\r  {frame} {self.message}... ({self._elapsed:.0f}s)")
            sys.stdout.flush()
            i += 1
            self._stop.wait(0.12)
        # ç»“æŸæ—¶æ¸…è¡Œ
        sys.stdout.write(f"\r  âœ“ {self.message} å®Œæˆ ({self._elapsed:.0f}s)   \n")
        sys.stdout.flush()

    def __enter__(self):
        self._thread = threading.Thread(target=self._spin, daemon=True)
        self._thread.start()
        return self

    def __exit__(self, *args):
        self._stop.set()
        self._thread.join()


# ============================================================
# æ ¸å¿ƒé€»è¾‘
# ============================================================

def get_wheel_package_name(filename: str) -> str:
    """ä» wheel æ–‡ä»¶åæå–åŒ…å (è§„èŒƒåŒ–ä¸ºå°å†™+ä¸‹åˆ’çº¿)"""
    parts = filename.split("-")
    return parts[0].lower().replace("-", "_")


def get_wheel_version(filename: str) -> str:
    """ä» wheel æ–‡ä»¶åæå–ç‰ˆæœ¬å·"""
    parts = filename.split("-")
    return parts[1] if len(parts) >= 2 else "unknown"


def get_existing_wheels(packages_dir: Path) -> dict:
    """è·å–å·²æœ‰çš„ wheel æ–‡ä»¶ {è§„èŒƒåŒ–åŒ…å: æ–‡ä»¶å}ï¼Œå¸¦è¿›åº¦æ¡"""
    wheels = {}
    if not packages_dir.exists():
        return wheels

    all_files = [f for f in packages_dir.iterdir() if f.is_file()]
    total = len(all_files)

    for i, f in enumerate(all_files):
        progress_bar(i + 1, total, prefix="æ‰«æç°æœ‰åŒ…")
        if f.suffix == ".whl":
            pkg_name = get_wheel_package_name(f.name)
            wheels[pkg_name] = f.name
        elif f.name.endswith((".tar.gz", ".zip")):
            wheels[f.stem.split("-")[0].lower().replace("-", "_")] = f.name

    return wheels


def detect_version_updates(packages_dir: Path, before_wheels: dict) -> dict:
    """
    æ£€æµ‹ç‰ˆæœ¬æ›´æ–°ï¼šæ‰«æç›®å½•ä¸­åŒååŒ…æ˜¯å¦æœ‰å¤šä¸ªç‰ˆæœ¬æ–‡ä»¶ã€‚
    pip download ä¼šä¸‹è½½æ–°ç‰ˆæœ¬ä½†ä¸åˆ é™¤æ—§ç‰ˆæœ¬ï¼Œå¯¼è‡´åŒåŒ…å¤šæ–‡ä»¶ã€‚
    è¿”å› {åŒ…å: {"old": æ—§æ–‡ä»¶å, "new": æ–°æ–‡ä»¶å}}
    """
    from collections import defaultdict

    # æŒ‰åŒ…ååˆ†ç»„æ‰€æœ‰æ–‡ä»¶
    pkg_files = defaultdict(list)
    for f in packages_dir.iterdir():
        if f.suffix == ".whl":
            pkg_name = get_wheel_package_name(f.name)
            pkg_files[pkg_name].append(f.name)

    updates = {}
    for pkg_name, files in pkg_files.items():
        if len(files) > 1:
            # å¤šä¸ªç‰ˆæœ¬å­˜åœ¨ï¼Œæ—§çš„æ˜¯ before ä¸­çš„ï¼Œæ–°çš„æ˜¯å¦ä¸€ä¸ª
            old_file = before_wheels.get(pkg_name)
            if old_file and old_file in files:
                new_files = [f for f in files if f != old_file]
                if new_files:
                    new_file = new_files[0]
                    old_ver = get_wheel_version(old_file)
                    new_ver = get_wheel_version(new_file)
                    updates[pkg_name] = {
                        "old_file": old_file, "new_file": new_file,
                        "old_ver": old_ver, "new_ver": new_ver
                    }
                    # åˆ é™¤æ—§ç‰ˆæœ¬
                    old_path = packages_dir / old_file
                    if old_path.exists():
                        old_path.unlink()
                        print(f"  ğŸ”„ ç‰ˆæœ¬æ›´æ–°: {pkg_name} {old_ver} â†’ {new_ver}")

    return updates

    return wheels


def get_required_packages(pip_exe: str, requirements_file: str) -> set:
    """é€šè¿‡ pip è§£æ requirements.txt çš„å®Œæ•´ä¾èµ–æ ‘ï¼Œå¸¦ Spinner åŠ¨ç”»"""
    # æ–¹æ¡ˆ1: pip download --dry-run --report
    with Spinner("è§£æä¾èµ–æ ‘ (dry-run)") as sp:
        try:
            result = subprocess.run(
                [pip_exe, "download", "-r", requirements_file,
                 "--dry-run", "--report", "-", "--quiet",
                 "--python-version", "3.10",
                 "--only-binary", ":all:",
                 "--platform", "win_amd64"],
                capture_output=True, text=True, timeout=120
            )
            if result.returncode == 0 and result.stdout.strip():
                try:
                    report = json.loads(result.stdout)
                    packages = set()
                    for item in report.get("install", []):
                        name = item.get("metadata", {}).get("name", "")
                        if name:
                            packages.add(name.lower().replace("-", "_"))
                    if packages:
                        return packages
                except json.JSONDecodeError:
                    pass
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass

    # æ–¹æ¡ˆ2: å›é€€ï¼Œpip download åˆ°ä¸´æ—¶ç›®å½•
    import tempfile
    with Spinner("è§£æä¾èµ–æ ‘ (å›é€€æ–¹æ¡ˆï¼Œéœ€è¦æ›´é•¿æ—¶é—´)") as sp:
        with tempfile.TemporaryDirectory() as tmpdir:
            result = subprocess.run(
                [pip_exe, "download", "-r", requirements_file,
                 "-d", tmpdir,
                 "--python-version", "3.10",
                 "--only-binary", ":all:",
                 "--platform", "win_amd64"],
                capture_output=True, text=True, timeout=600
            )
            if result.returncode != 0:
                result = subprocess.run(
                    [pip_exe, "download", "-r", requirements_file, "-d", tmpdir],
                    capture_output=True, text=True, timeout=600
                )

            packages = set()
            for f in Path(tmpdir).iterdir():
                if f.suffix == ".whl":
                    packages.add(get_wheel_package_name(f.name))
            return packages


def download_missing(pip_exe: str, requirements_file: str, packages_dir: Path):
    """ä¸‹è½½ç¼ºå¤±çš„ wheel åŒ…ï¼Œæµå¼è¾“å‡º pip è¿›åº¦"""
    print("  â¬‡ æ£€æŸ¥å¹¶ä¸‹è½½ç¼ºå¤±çš„ä¾èµ–...")

    process = subprocess.Popen(
        [pip_exe, "download", "-r", requirements_file,
         "-d", str(packages_dir),
         "--python-version", "3.10",
         "--only-binary", ":all:",
         "--platform", "win_amd64"],
        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
        text=True, bufsize=1
    )

    downloaded = 0
    skipped = 0
    for line in process.stdout:
        line = line.strip()
        if not line:
            continue
        if "already satisfied" in line.lower() or "File was already downloaded" in line:
            skipped += 1
            sys.stdout.write(f"\r  â­ å·²æœ‰: {skipped} | æ–°å¢: {downloaded}")
            sys.stdout.flush()
        elif "Saved" in line or "saved" in line.lower():
            downloaded += 1
            sys.stdout.write(f"\r  â­ å·²æœ‰: {skipped} | æ–°å¢: {downloaded}")
            sys.stdout.flush()

    process.wait()
    sys.stdout.write(f"\r  âœ“ ä¸‹è½½å®Œæˆ â€” è·³è¿‡: {skipped}, æ–°å¢: {downloaded}   \n")
    sys.stdout.flush()

    if process.returncode != 0:
        print("  [WARNING] éƒ¨åˆ†åŒ…ä¸æ”¯æŒ only-binaryï¼Œå°è¯•åŒ…å«æºç åŒ…...")
        subprocess.run(
            [pip_exe, "download", "-r", requirements_file,
             "-d", str(packages_dir)],
            timeout=600
        )

    return process.returncode == 0


def main():
    # backend/scripts/sync_offline_packages.py -> backend/scripts -> backend -> é¡¹ç›®æ ¹
    project_root = Path(__file__).parent.parent.parent
    packages_dir = project_root / "offline_packages"
    export_log_dir = project_root / "exportLog"
    requirements_file = str(project_root / "backend" / "requirements.txt")

    # ç¡®å®š pip è·¯å¾„
    venv_pip = project_root / ".venv" / "Scripts" / "pip.exe"
    runtime_pip = project_root / "runtime" / "python" / "Scripts" / "pip.exe"
    if venv_pip.exists():
        pip_exe = str(venv_pip)
    elif runtime_pip.exists():
        pip_exe = str(runtime_pip)
    else:
        print("[ERROR] æœªæ‰¾åˆ° pipï¼Œè¯·ç¡®ä¿ .venv æˆ– runtime/python å­˜åœ¨ã€‚")
        sys.exit(1)

    packages_dir.mkdir(exist_ok=True)
    export_log_dir.mkdir(exist_ok=True)

    # ===== 1. è®°å½•åŒæ­¥å‰çš„çŠ¶æ€ =====
    print()
    before_wheels = get_existing_wheels(packages_dir)
    print(f"  ğŸ“¦ å½“å‰ç¦»çº¿åŒ…: {len(before_wheels)} ä¸ª")
    print()

    # ===== 2. è·å–å®Œæ•´ä¾èµ–åˆ—è¡¨ =====
    required_packages = get_required_packages(pip_exe, requirements_file)
    print(f"  ğŸ“‹ éœ€è¦çš„åŒ…: {len(required_packages)} ä¸ª")
    print()

    # ===== 3. ä¸‹è½½ç¼ºå¤±çš„åŒ… =====
    download_missing(pip_exe, requirements_file, packages_dir)
    print()

    # ===== 4. æ£€æµ‹ç‰ˆæœ¬æ›´æ–° =====
    version_updates = detect_version_updates(packages_dir, before_wheels)

    # ===== 5. åŒæ­¥åè·å–æ–°çŠ¶æ€ =====
    after_wheels = get_existing_wheels(packages_dir)

    # ===== 6. è®¡ç®—å·®å¼‚ =====
    added_names = set(after_wheels.keys()) - set(before_wheels.keys())
    removed_candidates = set(before_wheels.keys()) - required_packages

    # å®é™…åˆ é™¤å¤šä½™çš„ wheel æ–‡ä»¶
    actually_removed = {}
    for pkg_name in removed_candidates:
        if pkg_name in before_wheels:
            file_to_remove = packages_dir / before_wheels[pkg_name]
            if file_to_remove.exists():
                actually_removed[pkg_name] = before_wheels[pkg_name]
                file_to_remove.unlink()
                print(f"  ğŸ—‘ åˆ é™¤: {before_wheels[pkg_name]}")

    # ===== 7. ç”Ÿæˆæ—¥å¿— + æ‹·è´æ–°å¢ wheel =====
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_session_dir = export_log_dir / timestamp
    log_session_dir.mkdir(exist_ok=True)

    log_lines = []
    log_lines.append(f"docBrain ç¦»çº¿åŒ…åŒæ­¥æ—¥å¿—")
    log_lines.append(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    log_lines.append(f"{'='*50}")
    log_lines.append(f"")
    log_lines.append(f"åŒæ­¥å‰åŒ…æ•°é‡: {len(before_wheels)}")
    log_lines.append(f"åŒæ­¥ååŒ…æ•°é‡: {len(after_wheels) - len(actually_removed)}")
    log_lines.append(f"éœ€è¦çš„åŒ…æ€»æ•°: {len(required_packages)}")
    log_lines.append(f"")

    if added_names:
        log_lines.append(f"[æ–°å¢] ({len(added_names)} ä¸ª)")
        new_wheels_dir = log_session_dir / "new_wheels"
        new_wheels_dir.mkdir(exist_ok=True)
        for pkg_name in sorted(added_names):
            filename = after_wheels[pkg_name]
            log_lines.append(f"  + {filename}")
            src = packages_dir / filename
            if src.exists():
                shutil.copy2(src, new_wheels_dir / filename)
    else:
        log_lines.append("[æ–°å¢] æ— ")

    log_lines.append(f"")

    if actually_removed:
        log_lines.append(f"[åˆ é™¤] ({len(actually_removed)} ä¸ª)")
        for pkg_name in sorted(actually_removed):
            log_lines.append(f"  - {actually_removed[pkg_name]}")
    else:
        log_lines.append("[åˆ é™¤] æ— ")

    log_lines.append(f"")

    if version_updates:
        log_lines.append(f"[ç‰ˆæœ¬æ›´æ–°] ({len(version_updates)} ä¸ª)")
        update_wheels_dir = log_session_dir / "updated_wheels"
        update_wheels_dir.mkdir(exist_ok=True)
        for pkg_name in sorted(version_updates):
            info = version_updates[pkg_name]
            log_lines.append(f"  â†‘ {pkg_name}: {info['old_ver']} â†’ {info['new_ver']}")
            log_lines.append(f"    æ—§: {info['old_file']}")
            log_lines.append(f"    æ–°: {info['new_file']}")
            # æ‹·è´æ–°ç‰ˆæœ¬ wheel åˆ°æ—¥å¿—ç›®å½•
            src = packages_dir / info['new_file']
            if src.exists():
                shutil.copy2(src, update_wheels_dir / info['new_file'])
    else:
        log_lines.append("[ç‰ˆæœ¬æ›´æ–°] æ— ")

    log_lines.append(f"")
    log_lines.append(f"{'='*50}")

    if not added_names and not actually_removed and not version_updates:
        log_lines.append("æ‰€æœ‰ä¾èµ–å·²æ˜¯æœ€æ–°ï¼Œæ— å˜æ›´ã€‚")

    log_content = "\n".join(log_lines)
    log_file = log_session_dir / "sync_log.txt"
    log_file.write_text(log_content, encoding="utf-8")

    # æ‰“å°æ‘˜è¦
    print()
    print(f"  {'='*40}")
    print(f"  åŒæ­¥å®Œæˆ:")
    print(f"    âœ… æ–°å¢: {len(added_names)} ä¸ªåŒ…")
    print(f"    ğŸ”„ ç‰ˆæœ¬æ›´æ–°: {len(version_updates)} ä¸ªåŒ…")
    print(f"    ğŸ—‘ åˆ é™¤: {len(actually_removed)} ä¸ªåŒ…")
    print(f"    ğŸ“„ æ—¥å¿—: exportLog/{timestamp}/sync_log.txt")
    if added_names:
        print(f"    ğŸ“¦ æ–°å¢wheelå‰¯æœ¬: exportLog/{timestamp}/new_wheels/")
    if version_updates:
        print(f"    ğŸ“¦ æ›´æ–°wheelå‰¯æœ¬: exportLog/{timestamp}/updated_wheels/")
    print(f"  {'='*40}")


if __name__ == "__main__":
    main()
